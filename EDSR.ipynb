{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9c44da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43f2224b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the EDSR model\n",
    "class EDSR(nn.Module):\n",
    "    def __init__(self, scale_factor=2, num_blocks=4, num_channels=128):\n",
    "        super(EDSR, self).__init__()\n",
    "        # Initial convolution layer\n",
    "        self.conv1 = nn.Conv2d(3, num_channels, kernel_size=3, padding=1)\n",
    "        # Residual blocks\n",
    "        self.res_blocks = nn.Sequential(\n",
    "            *[ResidualBlock(num_channels) for _ in range(num_blocks)]\n",
    "        )\n",
    "        # Another convolution layer\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        # Upsampling layer\n",
    "        self.upsample = nn.Sequential(\n",
    "            nn.Conv2d(num_channels, num_channels * scale_factor ** 2, kernel_size=3, padding=1),\n",
    "            nn.PixelShuffle(scale_factor)\n",
    "        )\n",
    "        # Final convolution layer\n",
    "        self.conv3 = nn.Conv2d(num_channels, 3, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        residual = out\n",
    "        out = self.res_blocks(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual  # Skip connection\n",
    "        out = self.upsample(out)\n",
    "        out = self.conv3(out)\n",
    "        return out\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, num_channels):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(num_channels, num_channels, kernel_size=3, padding=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        out = self.conv1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out += residual  # Skip connection\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "889b4170",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LRHRPairDataset(Dataset):\n",
    "    def __init__(self, root_dir, lr_transform=None, hr_transform=None, scale_factor=2):\n",
    "        self.scale_factor = scale_factor\n",
    "        self.root_dir = root_dir\n",
    "        self.lr_transform = lr_transform\n",
    "        self.hr_transform = hr_transform\n",
    "        self.image_filenames = [f for f in os.listdir(root_dir)]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filename = self.image_filenames[idx]\n",
    "        image_path = os.path.join(self.root_dir + \"\\\\\", image_filename)\n",
    "        # Load the HR image\n",
    "        hr_image = Image.open(image_path).convert(\"RGB\")\n",
    "        lr_image = hr_image.resize((hr_image.width // self.scale_factor, hr_image.height // self.scale_factor), Image.BICUBIC)\n",
    "        if self.lr_transform:\n",
    "            lr_image = self.lr_transform(lr_image)\n",
    "        if self.hr_transform:\n",
    "            hr_image = self.hr_transform(hr_image)\n",
    "        return lr_image, hr_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58e4e66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data transforms (you can customize these)\n",
    "lr_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])\n",
    "hr_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert to tensor\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bf0317e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "num_epochs = 20\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c405556",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = r\"D:\\COMPUTER ENGINEERING\\SEMESTER 7\\ML\\Project\\train_LR\"\n",
    "# Create a DataLoader for LR-HR pairs\n",
    "dataset = LRHRPairDataset(root_dir=dataset_path, lr_transform=lr_transform, hr_transform=hr_transform)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19419924",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EDSR().to(device)\n",
    "model.train()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "47c1b0d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1..\n",
      "Epoch [1/20] Loss: 0.07188567243167199\n",
      "Training Epoch 2..\n",
      "Epoch [2/20] Loss: 0.00566643635625951\n",
      "Training Epoch 3..\n",
      "Epoch [3/20] Loss: 0.00551321601960808\n",
      "Training Epoch 4..\n",
      "Epoch [4/20] Loss: 0.004954555051517673\n",
      "Training Epoch 5..\n",
      "Epoch [5/20] Loss: 0.0048339261912042275\n",
      "Training Epoch 6..\n",
      "Epoch [6/20] Loss: 0.004764156247256323\n",
      "Training Epoch 7..\n",
      "Epoch [7/20] Loss: 0.004728495594463311\n",
      "Training Epoch 8..\n",
      "Epoch [8/20] Loss: 0.004983787848614156\n",
      "Training Epoch 9..\n",
      "Epoch [9/20] Loss: 0.00470901706663426\n",
      "Training Epoch 10..\n",
      "Epoch [10/20] Loss: 0.004656810942688026\n",
      "Training Epoch 11..\n",
      "Epoch [11/20] Loss: 0.004645269777392968\n",
      "Training Epoch 12..\n",
      "Epoch [12/20] Loss: 0.004633926360402257\n",
      "Training Epoch 13..\n",
      "Epoch [13/20] Loss: 0.004627035671146587\n",
      "Training Epoch 14..\n",
      "Epoch [14/20] Loss: 0.004660168158588931\n",
      "Training Epoch 15..\n",
      "Epoch [15/20] Loss: 0.004669427409535274\n",
      "Training Epoch 16..\n",
      "Epoch [16/20] Loss: 0.004770465261535719\n",
      "Training Epoch 17..\n",
      "Epoch [17/20] Loss: 0.004629591158009134\n",
      "Training Epoch 18..\n",
      "Epoch [18/20] Loss: 0.004616397250210866\n",
      "Training Epoch 19..\n",
      "Epoch [19/20] Loss: 0.004628144428716041\n",
      "Training Epoch 20..\n",
      "Epoch [20/20] Loss: 0.004571132613054942\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    print(f\"Training Epoch {epoch + 1}..\", end=\"\\n\")\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    for batch in dataloader:\n",
    "        # Load and preprocess data\n",
    "        input_images, target_images = batch\n",
    "        input_images = input_images.cuda()\n",
    "        target_images = target_images.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass\n",
    "        outputs = model(input_images)\n",
    "        # Compute the loss\n",
    "        loss = criterion(outputs, target_images)\n",
    "        del input_images\n",
    "        del target_images\n",
    "        del outputs\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {total_loss / len(dataloader)}\", end=\"\\n\")\n",
    "torch.save(model.state_dict(), 'EDSRv4.50.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df111d19",
   "metadata": {},
   "source": [
    "## EXPORTING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddfb568a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scripted = torch.jit.script(model)\n",
    "model_scripted.save('./saved_models/EDSRx2v4.20.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2d9af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "image-enhancer",
   "language": "python",
   "name": "image-enhancer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
